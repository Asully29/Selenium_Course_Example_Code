# Automating Your Test Runs

You'll probably get a lot of mileage out of your test suite in its current form if you just run things from your computer, look at the results, and inform people when there are issues. But that only helps you solve part of the problem.

The real goal in all of this is to find issues reliably, quickly, and _automatically_. We've built things to be reliable and quick. Now we need to make them run automatically -- and ideally in sync with the development workflow you are a part of. In order to do that, we want to use a Continuous Integration (CI) server.

## A Continuous Integration Primer

Continous Integration (a.k.a. CI) is the practice of merging code that is actively being worked on into a shared mainline (e.g., trunk or master) as often as possible (e.g., several times a day). This is with the hopes of finding issues early and avoiding merging and integration issues that are not only considered a special kind of hell, but can dramatically slow the time it takes to release software.

The use of a CI server (a.k.a. build server) enables this practice to be automated, and to have tests run as part of the work flow. The lion's share of tests that are typically run on a CI Server are unit (and potentially integration) tests. But we can very easily add in our Selenium tests.

There are numerous CI Servers available for use today, most notably:

+ [Bamboo](https://www.atlassian.com/software/bamboo)
+ [Jenkins](http://jenkins-ci.org/)
+ [Solano Labs](solanolabs.com)
+ [TravisCI](https://travis-ci.org/)

## Part 1: Tagging & Workflow

In order to get the most out of our test runs in a CI environment we want to break up our test suite into small, relevant chunks and have separate jobs for each. This helps keep test runs fast and informative (so people on your team will care about them). [Gojko Adzic refers to these as "Test Packs"](http://gojko.net/2011/05/16/setting-up-a-build-pipeline-in-a-legacy-environment/).

The workflow is pretty straightforward. The CI Server pulls in the latest code, merges it, and runs unit tests. We then have the CI Server kick off a new job to deploy to a test server and run a subset of critical acceptance tests (e.g., smoke or sanity tests). Assuming those pass, we can have another job run the remaining tests after that (e.g., the less critical and longer running tests). [Adam Goucher refers to this strategy as a 'shallow' and 'deep' tagging model](https://github.com/adamgoucher/rspec-selenium-pageobjects#tags).

To demonstrate this, let's tag our tests and update our rake tasks to support tags.

### An Example

RSpec comes built in with tagging support. It's a simple matter of adding a key/value pair or a symbol to denote what you want. You can place it on individual tests, or a group of tests. And you can use as many tags as you want (separating them with commas).

Let's add some to our specs, following Adam Goucher's shallow and deep approach.

```ruby
# filename: spec/dynamic_loading_spec.rb
# ...
describe 'Dynamic Loading', :deep do
# ...
```

```ruby
# filename: spec/login_spec.rb
# ...
describe 'Login', :shallow do
# ...
```

If we wanted to apply this tag directly to a test, then it would look like this:

```ruby
it 'succeeded', :shallow do
```

To run tests based on a specific tag, we will need to pass in an additional argument to RSpec. It starts with `--tag` followed by the tag value (e.g., `--tag shallow` or `--tag deep`).

Let's update our 'Rakefile' tasks to handle this.

```ruby
# filename: Rakefile
def launch_with(config_filename)
  if ENV['tag']
    test_options = "-r ./config/#{config_filename} --order random --tag #{ENV['tag']}"
  else
    test_options = "-r ./config/#{config_filename} --order random"
  end
  system("parallel_rspec --test-options '#{test_options}' spec")
end
# ...
```

By updating our `launch_in_parallel` method to use a conditional based on the existence of the tag environment variable (`ENV['tag']`), we are able to dynamically alter our execution string at run time without having to change any of our tasks.

We just have to specify the tags at run time before our rake task (similar to how we would specify a different `base_url`).

```sh
tag=shallow rake local:firefox
```

## Part 2: Reporting

In order to make our test output useful for a CI Server we need to generate it in a standard way. One format that works across all CI Servers is JUnit XML.

### An Example

This functionality doesn't come built into RSpec, but it's simple enough to add through the use of a third-party library. There are plenty to choose from, but we'll go with ['rspec\_junit\_formatter'](https://github.com/sj26/rspec_junit_formatter).

```ruby
# filename: Gemfile
source 'https://rubygems.org'

gem 'rspec', '~> 3.4.0'
gem 'selenium-webdriver', '2.48.1'
gem 'sauce_whisk', '~> 0.0.19'
gem 'parallel_tests', '~> 2.0.0'
gem 'rake', '~> 10.4.2'
gem 'rspec_junit_formatter', '~> 0.2.3'
```

After we install it we need to specify the formatter type and an output file for RSpec to consume. This is done through the use of two new arguments; `--format RspecJunitFormatter` and `--out results.xml`. But in order to use this with our parallel test execution we need to create a uniquely named XML output file for _each_ test process. To accomplish that with `parallel_tests` we will need to take advantage of another feature in RSpec -- the `.rspec` file.

RSpec comes with the ability to place command arguments in a `.rspec` file within the root directory of our project, which will automatically be consumed at runtime. So we'll place our new arguments there, and use a kind of interpolation to inject an environment variable from `parallel_tests` which will be unique for each test process.

We're doing this instead of adding it to the `launch_in_parallel` method in our 'Rakefile' because of how parallel_tests handles execution. In order to get dynamically named XML output, we have to use the `.rspec` file in order to get the timing right. Also, we don't want our XML output to happen all the time. So let's also make it so the commands in `.rspec` only run when we want them to.

```
# filename: .rspec
<% if ENV['ci'] == 'on' %>
--format RspecJunitFormatter
--out results/result<%= ENV['TEST_ENV_NUMBER'] %>.xml
<% end %>
```

When we run our tests with the `ci` environment variable set to `'on'` (e.g., `ci=on rake local:firefox`), each test process creates it's own `result.xml` by number (e.g., `result.xml`, `result2.xml`, etc.), and ends up in a `results` directory.

After a test run our directory structure will look like this:

```sh
.
├── Gemfile
├── Gemfile.lock
├── Rakefile
├── config
│   ├── cloud.rb
│   └── local.rb
├── pages
│   ├── base_page.rb
│   ├── dynamic_loading.rb
│   └── login.rb
├── results
│   ├── result.xml
│   └── result2.xml
├── spec
│   ├── dynamic_loading_spec.rb
│   ├── login_spec.rb
│   └── spec_helper.rb
└── vendor
    ├── chromedriver
    └── sauce-connect
        ├── bin
        │   ├── sc
        │   └── sc.dSYM
        │       └── Contents
        │           ├── Info.plist
        │           └── Resources
        │               └── DWARF
        │                   └── sc
        ├── include
        │   └── sauceconnect.h
        ├── lib
        │   ├── libsauceconnect.a
        │   └── libsauceconnect.la
        └── license.html
```

If we open one of the XML files from the `results` directory, it will contain a bunch of info from the test run. This is what our CI server will use to track test results (e.g., passes, failures, time to complete, etc.) and trend them over time.

Here's what one from a passing run looks like.

```xml
<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="rspec" tests="2" failures="0" errors="0" time="25.890860" timestamp="2015-11-21T11:35:05-05:00">
  <!-- Randomized with seed 5604 -->
  <properties/>
  <testcase classname="spec.dynamic_loading_spec" name="Dynamic Loading Example 1: Hidden Element" file="./spec/dynamic_loading_spec.rb" time="13.115928"/>
  <testcase classname="spec.dynamic_loading_spec" name="Dynamic Loading Example 2: Rendered after the fact" file="./spec/dynamic_loading_spec.rb" time="12.774309"/>
</testsuite>

```

We don't want to commit the XML files our repository, so let's add them to our ignore file.

```text
# filename: .gitignore

*.xml
```

In this case we're using [Git](https://git-scm.com/). If you're using something else (e.g., [Mercurial](https://www.mercurial-scm.org/), [Subversion](https://subversion.apache.org/), etc.) then find it's ignore file equivalent and use it.

Now we're ready to wire things up to our CI server.

## Part 3: CI Server Job Configuration

[Jenkins](http://jenkins-ci.org/) is a fully functional, widely adopted, and open-source CI server. Its a great candidate for us to step through.

Lets start by setting it up on the same machine as our test code. Keep in mind that this isn’t the "proper" way to go about this — its merely beneficial for this example. To do it right, the Jenkins server (e.g., master node) would live on a machine of its own.

### 1. Quick Setup

A simple way to get started is to grab the latest Jenkins war file. You can grab it from the [Jenkins homepage](http://jenkins-ci.org/), or from [the direct download link on the homepage](http://mirrors.jenkins-ci.org/war/latest/jenkins.war).

Once downloaded, launch it from the terminal.

```sh
> java -jar jenkins.war
...
INFO: Jenkins is fully up and running
```

You will now be able to use Jenkins by visiting http://localhost:8080/ in your browser.

![Jenkins Home Screen](screenshot_jenkins1_home.png)

__NOTE: Before moving to the next step, click `ENABLE AUTO-REFRESH` at the top right-hand side of the page. Otherwise you'll need to manually refresh the page (e.g., when running a job and waiting for results to appear).__

### 2. Job Creation and Configuration

Now that Jenkins is loaded in the browser, let's create a Job and configure it to run our Shallow tests against an old version of Internet Explorer (e.g., IE8).

+ Click `New Item` from the top-left of the Dashboard
+ Give it a name (e.g., `Shallow Tests IE8`)
+ Select the `Freestyle Project` option
+ Click `OK`

![Jenkins New Job](screenshot_jenkins2_new_job.png)

This will load a configuration screen for the Jenkins job.

![Jenkins Job Configuration](screenshot_jenkins3_job_config.png)

+ Under `Advanced Project Options` click `Advanced...`
+ Check the box next to `Use custom workspace`
+ In the input field next to `Directory` input the full path to your test code

__NOTE: Ideally, your test code would live in a version control system and you would configure your job (under `Source Code Management`) to pull it in and run it. To use this approach you may need to install a plugin to handle it (depending on your version control solution). For more info on plugins in Jenkins, go [here](https://wiki.jenki    ns-ci.org/display/JENKINS/Plugins).__

![Jenkins Job Configuration Advanced](screenshot_jenkins4_job_config_advanced.png)

+ Scroll down until you reach the `Build` section (near the bottom of the page)
+ Click on `Add build step` and select `Execute Shell`

![Jenkins Job Configuration Execute Shell](screenshot_jenkins5_job_build_execute_shell.png)

In the Command input box, add the following commands:

```sh
export SAUCE_USERNAME="your-sauce-username"
export SAUCE_ACCESS_KEY="your-sauce-access-key"
gem install bundler
bundle install
ci=on bundle rake cloud:internet_explorer['8','Windows XP']
```

![Jenkins Build](screenshot_jenkins6_job_build_execute_shell_command.png)

Since our tests have never run on this server we need to include the installation and running of the bundler gem (`gem install bundler` and `bundle install`) to download and install the libraries (a.k.a. gems) used in our test suite. And we also need to specify our credentials for Sauce Labs (unless you decided to hard-code these values in `config/cloud.rb` - if so, then you don't need to specify them here).

Now we need to consume the JUnit XML that our test suite will generate.

+ Click on `Add post-build action`
+ Select `Publish JUnit test result report`

![Jenkins Job Post Build Action Selection](screenshot_jenkins7_post_build_action_selection.png)

+ In the input box to the right of `Test Report XMLs` type `results/*.xml`

![Jenkins Job Post Build Action XMLs](screenshot_jenkins8_post_build_action_xmls.png)

Now we're ready to save, run our tests, and view the job result.

+ Click `Save`
+ Click `Build Now` from the left-hand side of the screen

When the build completes, the result will be listed on the job's home screen. In this case, the job passed.

![Jenkins Job Result From First Run](screenshot_jenkins9_job_passed.png)

__NOTE: If you had a different result, you can drill into a job to see what was happening behind the scenes. To do that click on the build you want from `Build History` and select `Console Output`. This output will be your best bet in tracking down an unexpected result.__

A passing job means passing tests, which is great. But we'll also want to see what a failure looks like to make sure its helpful.

### Part 3: Force A Failure

Let's add a new test to `spec/login_spec.rb` that will fail every time we run it.

```ruby
# filename: spec/login_spec.rb
# ...
  it 'forced failure' do
    expect(false).to eql true
  end

end
```

Now when we run our Jenkins job again, it will fail.

![Jenkins Job Screen With Failure](screenshot_jenkins10_job_failed.png)

When we click on the failed test we can see the failure message along with a URL to the job in Sauce Labs.

![Jenkins Job Test Result](screenshot_jenkins11_job_stacktrace.png)

When we follow the URL to the Sauce Labs job we're able to see what happened during the test run (e.g., we can replay a video of the test, see what Selenium commands were issued, etc.).

![Sauce Labs Job](screenshot_jenkins12_sauce_job.png)

## Notifications

In order to maximize your CI effectiveness, you'll want to send out notifications to alert your team members when there's a failure.

There are numerous ways to go about this (e.g., e-mail, chat, text, co-located visual cues, etc). And thankfully there are numerous, freely available plugins that can help facilitate whichever method you want. You can find out more about Jenkins plugins [here](https://wiki.jenkins-ci.org/display/JENKINS/Plugins).

For instance, if you wanted to use chat notifications and you use a service like HipChat or Slack, you would do a plugin search and find the following plugins:

![Jenkins Plugin HipChat](screenshot_jenkins13_plugin_hipchat.png)
![Jenkins Plugin Slack](screenshot_jenkins14_plugin_slack.png)

After installing the plugin for your chat service, you will need to provide the necessary information to configure it (e.g., an authorization token, the channel/chat room where you want notifications to go, what kinds of notifications you want sent, etc.) and then add it as a `Post-build Action` to your job (or jobs).

After installing and configuring a plugin, when your CI job runs and fails, a notification will be sent to the chat room you configured.

## Outro

By using a CI Server you're able to put your tests to work by using computers for what they're good at, automation. This frees you up to focus on more important things. But keep in mind that there are numerous ways to configure your CI server. Be sure to tune it to what works best for you and your team. It's well worth the effort.
